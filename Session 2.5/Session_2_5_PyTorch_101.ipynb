{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzQ2Yo50q2jdmVWqSd1Dfu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mutum/Mutum-computer_vision_EVA/blob/main/Session%202.5/Session_2_5_PyTorch_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GTQaLvETZ0C2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.MNIST(\n",
        "    root=\"MNIST_data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "cSxih260aAHl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class custom_data():\n",
        "\n",
        "    def __init__(self,batch_size) -> None:\n",
        "        self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
        "        self.a_num_numpy = None\n",
        "        # self.a_num_torch = None\n",
        "        self.genrate_rand() \n",
        "     \n",
        "    def genrate_rand(self):\n",
        "        \n",
        "        a_num_numpy = np.random.choice(range(0,10,1))\n",
        "        # a_num_numpy = a_num_numpy.astype('float')\n",
        "        a_num_numpy_oneHot = np.array([1 if num == a_num_numpy else 0 for num in range(0,10) ])\n",
        "        a_num_torch = torch.from_numpy(a_num_numpy_oneHot)\n",
        "        \n",
        "        self.a_num_numpy = a_num_numpy\n",
        "        # self.a_num_torch = a_num_torch\n",
        "        \n"
      ],
      "metadata": {
        "id": "hhBOaZnHaB4-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) \n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "    self.out_sum = nn.Linear(in_features=60, out_features=18)\n",
        "    \n",
        "    # self.fc_rand = nn.Linear(in_features=192, out_features=192)\n",
        "\n",
        "  def forward(self, t, a_num_numpy):\n",
        "    # input layer\n",
        "    # here are the batch of images \n",
        "    x = t \n",
        "    # conv1 layer\n",
        "    x = self.conv1(x) \n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
        "    # conv2 layer\n",
        "    x = self.conv2(x) \n",
        "    x = F.relu(x) \n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
        "    # reshapre\n",
        "    x = x.reshape(-1, 12 * 4 * 4)\n",
        "\n",
        "    # the random number from 0-9 in numpy\n",
        "    x_rand = a_num_numpy\n",
        "\n",
        "    # add the random number to our previous image convolution layer\n",
        "    x_new = torch.add(x, x_rand)\n",
        "    \n",
        "    # fc1 layer\n",
        "    x_new = self.fc1(x_new)\n",
        "    x_new = F.relu(x_new)\n",
        "    \n",
        "    # fc2 layer\n",
        "    x_new = self.fc2(x_new)\n",
        "    x_new_ = F.relu(x_new)\n",
        "    \n",
        "    # output prediction for the \n",
        "    x_new = self.out(x_new_)\n",
        "\n",
        "    #  add for another output of the total_sum prediction\n",
        "    x_sum = self.out_sum(x_new_)\n",
        "    \n",
        "    return x_new, x_sum\n"
      ],
      "metadata": {
        "id": "spSl97slaJ7J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  \"\"\" return accurary \"\"\"\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()\n"
      ],
      "metadata": {
        "id": "NwnUzyQ5ay6_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initiating our data input \n",
        "\n",
        "# custom data class initiated\n",
        "training_data = custom_data(batch_size= 64)\n",
        "\n",
        "# images and labels\n",
        "train_loader = training_data.train_loader\n",
        "\n",
        "# the random number generated\n",
        "a_num_numpy = training_data.a_num_numpy \n"
      ],
      "metadata": {
        "id": "xM2zgRTCa6Lh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "\n",
        "network = Network()\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(20):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct_image = 0\n",
        "    total_correct_sum_output = 0\n",
        "\n",
        "    for batch in train_loader: # Get Batch\n",
        "        images, labels = batch \n",
        "        sum_labels = labels + a_num_numpy\n",
        "\n",
        "        preds, pred_sum = network(images, a_num_numpy) # Pass Batch\n",
        "        # print(preds.shape)\n",
        "        # loss = F.cross_entropy(preds, labels)\n",
        "        # pred_sum = pred_sum + x_rand\n",
        "        loss_1 = F.cross_entropy(preds, labels) # Calculate Loss\n",
        "        loss_2 = F.cross_entropy(pred_sum, sum_labels)\n",
        "\n",
        "        loss = loss_1 + loss_2\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() # Calculate Gradients\n",
        "        optimizer.step() # Update Weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct_image  += get_num_correct(preds, labels)\n",
        "        total_correct_sum_output += get_num_correct(pred_sum, sum_labels)\n",
        "\n",
        "    print(\n",
        "        \"epoch:\", epoch, \n",
        "        \" total_correct_image:\", total_correct_image , \n",
        "        \" total_correct_sum_output:\", total_correct_sum_output, \n",
        "        \" loss:\", total_loss\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD0h3x9Pa8ZF",
        "outputId": "555dd21f-2bc2-4aef-a4da-8d6dc49309fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  total_correct_image: 6356  total_correct_sum_output: 6313  loss: 4333.2324986457825\n",
            "epoch: 1  total_correct_image: 6496  total_correct_sum_output: 6465  loss: 4321.711705684662\n",
            "epoch: 2  total_correct_image: 6589  total_correct_sum_output: 6560  loss: 4320.180404663086\n",
            "epoch: 3  total_correct_image: 6640  total_correct_sum_output: 6658  loss: 4319.501060009003\n",
            "epoch: 4  total_correct_image: 6673  total_correct_sum_output: 6670  loss: 4319.139639377594\n",
            "epoch: 5  total_correct_image: 6682  total_correct_sum_output: 6675  loss: 4318.807169914246\n",
            "epoch: 6  total_correct_image: 6680  total_correct_sum_output: 6680  loss: 4318.538893699646\n",
            "epoch: 7  total_correct_image: 6694  total_correct_sum_output: 6694  loss: 4318.357453346252\n",
            "epoch: 8  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.272194862366\n",
            "epoch: 9  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.239808082581\n",
            "epoch: 10  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.229818820953\n",
            "epoch: 11  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.225511550903\n",
            "epoch: 12  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.223289966583\n",
            "epoch: 13  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.2220277786255\n",
            "epoch: 14  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.221292972565\n",
            "epoch: 15  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.220851421356\n",
            "epoch: 16  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.220569610596\n",
            "epoch: 17  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.22039937973\n",
            "epoch: 18  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.2203068733215\n",
            "epoch: 19  total_correct_image: 6691  total_correct_sum_output: 6691  loss: 4318.220238208771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kZGFLbimjIjq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}